{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install swig\n",
    "# !pip install \"gymnasium[box2d]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cace0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().absolute().parent.parent\n",
    "results_dir = project_root / 'results'\n",
    "\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dqn import DQNAgent, DQNAgentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b8262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(DQNAgentConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Score: -110.35, Avg (last 20): -110.35, Epsilon: 0.68\n",
      "Episode 20, Score: -176.17, Avg (last 20): -237.89, Epsilon: 0.05\n",
      "Episode 40, Score: -156.15, Avg (last 20): -54.54, Epsilon: 0.05\n",
      "Episode 60, Score: 145.12, Avg (last 20): -51.61, Epsilon: 0.05\n",
      "Episode 80, Score: -145.00, Avg (last 20): -121.08, Epsilon: 0.05\n",
      "Episode 100, Score: -0.82, Avg (last 20): -74.39, Epsilon: 0.05\n",
      "Episode 120, Score: -32.83, Avg (last 20): -45.05, Epsilon: 0.05\n",
      "Episode 140, Score: 157.99, Avg (last 20): -2.95, Epsilon: 0.05\n",
      "Episode 160, Score: -64.84, Avg (last 20): -0.40, Epsilon: 0.05\n",
      "Episode 180, Score: -23.17, Avg (last 20): -29.83, Epsilon: 0.05\n",
      "Episode 200, Score: -3.46, Avg (last 20): 19.70, Epsilon: 0.05\n",
      "Episode 220, Score: -20.50, Avg (last 20): -24.23, Epsilon: 0.05\n",
      "Episode 240, Score: -58.33, Avg (last 20): 20.11, Epsilon: 0.05\n",
      "Episode 260, Score: 137.87, Avg (last 20): 15.84, Epsilon: 0.05\n",
      "Episode 280, Score: 257.22, Avg (last 20): 195.31, Epsilon: 0.05\n",
      "Episode 300, Score: 171.44, Avg (last 20): 156.25, Epsilon: 0.05\n",
      "Episode 320, Score: 252.72, Avg (last 20): 208.90, Epsilon: 0.05\n",
      "Episode 340, Score: 227.48, Avg (last 20): 244.19, Epsilon: 0.05\n",
      "Episode 360, Score: 206.34, Avg (last 20): 196.57, Epsilon: 0.05\n",
      "Episode 380, Score: 166.50, Avg (last 20): 187.92, Epsilon: 0.05\n",
      "Episode 400, Score: 172.12, Avg (last 20): 187.23, Epsilon: 0.05\n",
      "Episode 420, Score: 211.63, Avg (last 20): 220.38, Epsilon: 0.05\n",
      "Episode 440, Score: 261.10, Avg (last 20): 239.74, Epsilon: 0.05\n",
      "Episode 460, Score: 230.68, Avg (last 20): 237.69, Epsilon: 0.05\n",
      "Episode 480, Score: 242.49, Avg (last 20): 251.67, Epsilon: 0.05\n",
      "Episode 500, Score: 223.12, Avg (last 20): 237.67, Epsilon: 0.05\n",
      "Episode 520, Score: 257.95, Avg (last 20): 258.50, Epsilon: 0.05\n",
      "Episode 540, Score: 280.16, Avg (last 20): 257.55, Epsilon: 0.05\n",
      "Episode 560, Score: 258.81, Avg (last 20): 252.36, Epsilon: 0.05\n",
      "Episode 580, Score: 261.85, Avg (last 20): 237.09, Epsilon: 0.05\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i_episode in range(600): # Run for 600 episodes\n",
    "    state, info = agent.env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for t in range(1000):\n",
    "        action = agent.select_action(state)\n",
    "        \n",
    "        observation, reward, terminated, truncated, _ = agent.env.step(action.item())\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        agent.memory.push(state, action.item(), reward, observation, done)\n",
    "        agent.optimize_model()\n",
    "        \n",
    "        state = observation\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    scores.append(total_reward)\n",
    "    \n",
    "    # Logging\n",
    "    if i_episode % 20 == 0:\n",
    "        avg_score = np.mean(scores[-20:])\n",
    "        print(f\"Episode {i_episode}, Score: {total_reward:.2f}, Avg (last 20): {avg_score:.2f}, Epsilon: {agent.eps_end + (agent.eps_start - agent.eps_end) * math.exp(-1. * agent.steps_done / agent.eps_decay):.2f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net.state_dict(), results_dir / \"lunar_lander_dqn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8b848b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Episode 1 Score: 261.00\n",
      "Test Episode 2 Score: 298.20\n",
      "Test Episode 3 Score: 270.90\n",
      "Test Episode 4 Score: 228.09\n",
      "Test Episode 5 Score: 258.59\n"
     ]
    }
   ],
   "source": [
    "visual_env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "num_test_episodes = 5\n",
    "\n",
    "for ep in range(num_test_episodes):\n",
    "    state, info = visual_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Prepare the state for the network\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "        \n",
    "        # Ask the trained network for the best move\n",
    "        with torch.no_grad():\n",
    "            action_index = agent.policy_net(state_tensor).max(1)[1].item()\n",
    "        \n",
    "        # Take the action\n",
    "        state, reward, terminated, truncated, _ = visual_env.step(action_index)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f\"Test Episode {ep + 1} Score: {total_reward:.2f}\")\n",
    "\n",
    "visual_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847102d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
